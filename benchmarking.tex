% The first command in your LaTeX source must be the \documentclass command.


\documentclass[sigconf]{acmart}
\settopmatter{printacmref=true}

\fancyhead{}
  % do not delete this code.

\usepackage{balance}
  % for creating a balanced last page (usually last page with references)

% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
% Rights management information. 
% This information is sent to you when you complete the rights form.
% These commands have SAMPLE values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you complete the rights form.
%
% These commands are for a PROCEEDINGS abstract or paper.


% Submission ID. 
% Use this when submitting an article to a sponsored event. You'll receive a unique submission ID from the organizers
% of the event, and this ID should be used as the parameter to this command.
%\acmSubmissionID{123-A56-BU3}


% end of the preamble, start of the body of the document source.


\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{epsfig,url}
\usepackage{epsf}

%% Added by JJ
\usepackage{cleveref}
\usepackage{tabularx}
\usepackage{ragged2e}
%%

%Control space between caption and figure/table
\captionsetup[figure]{font=small,skip=5pt}
%\captionsetup[table]{font=small,skip=0pt}


\copyrightyear{2021}
\acmYear{2021}
\setcopyright{acmcopyright}\acmConference[ISPD '21]{Proceedings of the 2021 International Symposium on Physical Design}{March 22--24, 2021}{Virtual Event, USA}
\acmBooktitle{Proceedings of the 2021 International Symposium on Physical Design (ISPD '21), March 22--24, 2021, Virtual Event, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3439706.3446885}
\acmISBN{978-1-4503-8300-4/21/03}

\begin{document}


\title{Still Benchmarking After All These Years\\(Draft, Invited)}
\iffalse
\author{Blind Review}
\else
\author{Ismail S. K. Bustany}
\email{ISMAILB@xilinx.com}
\affiliation{
  \institution{Xilinx}
}
\author{Jinwook Jung}
\email{jinwookjung@ibm.com}
\affiliation{
  \institution{IBM T.J.\ Watson Research Center}
  \streetaddress{1101 Kitchawan Rd}
  \city{Yorktown Heights}
  \state{New York}
  \postcode{10598}
}
\author{Patrick H. Madden}
\email{pmadden@binghamton.edu}
\affiliation{
  \institution{SUNY Binghamton CSD}
  \streetaddress{Box 6000}
  \city{Binghamton}
  \state{New York}
  \postcode{13902}
}
\author{Natarajan Viswanathan}
\email{nviswan@cadence.com}
\affiliation{
  \institution{Cadence}
}
\author{Stephen Yang}
\email{stepheny@xilinx.com}
\affiliation{
  \institution{Xilinx}
}


 
\fi
\begin{abstract}
\input{abstract.tex}
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010583.10010682</concept_id>
       <concept_desc>Hardware~Electronic design automation</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Hardware~Electronic design automation}


%
% Keywords. The author(s) should pick words that accurately describe the work being
% presented. Separate the keywords with commas.

\keywords{benchmarking; circuit placement; metrics}

\maketitle

\section{Introduction}

Integrated circuits have evolved at a breakneck pace for decades.  The
first MOSFET transistors were created at the end of the 1950's, with
Moore\cite{Moore650114} making his bold prediction for exponential
growth in 1965.  While it might have seemed far-fetched or wildly
optimistic at the time, Moore's Law has been a relentless juggernaut.
In 1960, only a handful of transistors could be integrated into a
single device, but by 1980, just twenty years later, the Motorola
68000 had roughly sixty-eight thousand transistors.  Twenty years
after that, the Intel Pentium 4 featured roughly forty-two million
transistors.  Twenty years after that, in the era in which this paper
is being written, the Apple M1 processor has in excess of sixteen
billion transistors.

The technological advances required for this progress
have not been spontaneous.  At each
step along the way, researchers from both academia and
industry, and from a wide range of fields,
have been quietly identifying and overcoming
technological barriers.  The massive electronics industry,
which has impacted almost every aspect of modern life,
is the product of decades of hard work.

VLSI physical design focuses on translating the logical function
of a system into an equivalent physical representation.  Key
steps are logic synthesis -- translating a higher level system
specification into simple logic gates -- followed by finding
physical locations for each gate on a silicon die, and the
generation of interconnecting wires.  Each step in a physical
design flow is difficult, and automation is essential for
even modest sized problems.

Benchmarking, the practice of using example problems to compare
different solution approaches, has been critical to this progress.
Benchmarks that have well defined metrics, and that are widely
available, are most helpful; they can engage a broad audience, drawing
in contributions and ideas.  The market forces that have driven the
electronics industry forward have also in some ways been a barrier;
secrecy
around process technologies, circuit designs, and design methodologies
give a competitive advantage, and groups at the leading edge of
technology are often reluctant to reveal their secrets.

In this paper, we look back on how the role of benchmarking
in physical design, with an emphasis on circuit placement.
Following something of a rocky start, the physical design
community has found workable solutions that protects the
intellectual property of industry leaders, while also
opening up design benchmarks for the general public.
This has allowed
physical design to evolve to a state where sustained,
regular progress can be made.


% https://en.wikipedia.org/wiki/Transistor_count
% Better citation for stuff like this?
\iffalse
{\bf How to say this?
  Economic driver pushing technology forward.  Lots of
  companies competing for market share.  Secrecy on
  design technology, circuit designs, gives a competitive
  advantage -- but also limits the number of people who
  can solve the problems that need to be solved.

  For academic researchers in particular to be helpful,
  details of the problems needing solving have to be
  available.  Without test cases, and things that are
  suitable for publication, they cannot assist.
}




Making progress in design automation has been challenging;
the problems addressed are fundamentally hard from a scientific
perspective. Complicating matters further are the financial
implications -- semiconductor manufacturers, design tool companies,
and circuit designers, are all interested in making profits, and
this depends on some degree of secrecy in their work.  At the
same time, solving design problems requires assistance from
others.
\fi


\section{Placement Benchmarking}

The very earliest circuits were designed by hand, each one a custom
creation. As design sizes increased, and semiconductor fabrication
technologies became more refined, designers converged on a few
common conventions and abstractions, such as lambda-based design rules
and standard cell libraries\cite{Mead93}.  A design flow of logic
synthesis, to placement, and to routing, enabled interchangable
design automation tools and encouraged common design file formats.



\subsection{Metrics}
{\bf Simple Placement Metrics}

As the new benchmarks did not contain functional information,
timing models, and so forth, it was entirely practical to
simplify the file formats so that they were easy to parse.
Much of this work was done as part of the of the
GSRC ``bookshelf''\cite{umichbookshelf}, with many groups
contributing software tools and benchmark problems.

{\bf Complex Placement Metrics}



\subsection{Early Benchmarks}


There were few commonly available circuits and benchmark problems in
the early days.  In 1987, a panel discussion\cite{Preas87} highlighted
the need for good benchmarks for standard cell design, and a few years
later in 1991, the MCNC benchmarks\cite{Kozminski91} were presented
and quickly gained prominence.  The benchmarks are shown in Table
\ref{tab:mcnc} -- while they were not comparable in size and
complexity to the leading edge of industrial design, they filled a
vacuum, and were a catalyst for academic research.  The availability
of circuits that could be used as physical design benchmarks sparked a
wave of circuit placement research.

\begin{table}
  \begin{tabular}{|l|r|r|r|} \hline
Name & \# cells & \# nets & \# I/O \\ \hline
    fract   &   125 &   147 & 24 \\ \hline
   primary1 &   752 &   985 & 81 \\ \hline
    struct  &  1888 &  1920 & 64 \\ \hline
  industry1 &  2271 & 2593 & 814 \\ \hline
  primary2 & 2907 & 3136 & 107 \\ \hline
  biomed & 6417 & 5742 & 97 \\ \hline
  industry2 & 12142 & 13419 & 495 \\ \hline
  industry3 & 15059 & 21940 & 375 \\ \hline
  \end{tabular}
  \caption{The original MCNC standard cell
    benchmarks\cite{Kozminski91}.}\label{tab:mcnc}
\end{table}


There was hope that more benchmarks would
become available; Kozminski\cite{Kozminski91} noted the following:

\begin{quote}
It seems apparent that more benchmarks for layout synthesis are
needed, they should be more fully described, as discussed earlier in
the paper. In the opinion of the author, distributing pure
geometrical data is no longer sufficient for meaningful benchmarking
of algorithms used in real-life applications to produce working chip
layouts. The circuit's function as well as its speed and timing
requirements should be supplied together with technological data
required to verify the performance of the completed design. As an
unavoidable consequence, future benchmarks will have to come from
sources willing to put the information about logical functions of the
benchmark circuits in the public domain.
\end{quote}

A decade later, the original MCNC
benchmarks were still in wide use, and
the gap between academic research and
industrial practice had widened.
Even more troubling -- to try to keep pace, many research
groups were scaling and translating the benchmarks in
a variety of ways, resulting in massive variations in how
results were reported\cite{Madden010030}.

\subsection{From Partitioning to Placement}


Researchers in both academia and industry were troubled
by a lack of up-to-date physical benchmarks; what was
needed was a way to break the log-jam.
This break
arrived in the form of the release of ``ISPD98'' partitioning
benchmarks by Alpert\cite{Alpert980080}.

Alpert noted the following:
\begin{quote}
All information relating to circuit functionality, timing and
technology is removed. Unfortunately, this limits the direct
applicability of these circuits (e.g., functional replication for
partitioning); yet, the release of these circuits would have been
impossible otherwise. \cite{Alpert980080}
\end{quote}

Without functional information, reverse-engineering of the circuits
was impossible -- thus protecting intellectual property.
With the net list structure, however, it was possible to construct
a placement benchmark that could be used for an objective such
as wire length minimization -- Wang\cite{Wang000260} did this
for standard cells, with Adya\cite{Adya020012} taking the idea
further to address mixed-size placement.  

% industry practice\cite{Adya040472}.

After a number of years of little change, there was a burst of
activity.  The
GSRC supported GTX project \cite{Caldwell000693} provided a platform
to work from.

% ISPD98 partitioning benchmarks by Chuck

% Partition to placement
% \cite{Wang000260}
% Converted to mixed size placement in ISPD02 by Igor
% \cite{Adya020012}
% Mixed size placer PHM in ISPD04
% \cite{Khatkhate040084}
% ISPD05 -- Adaptec and Bigblue, fixed macros
% \cite{Nam050216}


% \subsection{Bookshelf File Formats}



% SIGDA newsletter! Franc Brglez from MCNC
% http://web.cs.ucla.edu/classes/layout/testing/Examples.iscas/ISCAS89/Benchmark.readme

% {\bf Talk about production file formats versus things that
%   are easy to parse.  Decisions made for GSRC Bookshelf.}

% \cite{Caldwell000693}\cite{umichbookshelf}




\section{The ISPD Contests}

% \subsection{Growing the Research Community}

While the most obvious objective for releasing a benchmark for some
problem $X$ is to be able to find better solutions for problem $X$,
there are other objectives as well.  Good benchmarks, particularly
ones that simplify a complex problem, provide a training ground for
students entering a field.

The technological advances that
have enabled the growth of the semiconductor industry
are due to the hard work of researchers from around the
world.  Every seasoned expert was at some point in their
career a beginning student.

While the new placement benchmarks lacked the detail needed
to create a fully functional circuit, they were more than
adequate for a student to understand the constraints, and
to experiment with new ideas.  The simplified file formats
allowed for rapid prototyping.

There is often a trade-off:
a simple problem, with a single metric, versus
a complex ``realistic'' problem, with multiple competing
objectives.  Spanning tree, Steiner tree, moving to clock
tree, where we measure skew, source to sink delay, jitter,
power consumption.  To routing, where multiple trees compete
for resources.
Partitioning -- simple problem to measure, impact when used
in a complex tool is muted.  Single step of a design automation
flow, version a complete run.

Good benchmarks can be used to direct the focus of researchers
on critical problems.


\iffalse
Secondary objectives.  Training ground for new students
entering the field -- a way to build understanding.  Simplified
construction of tools, lower time and effort required to
experiment with new ideas.
\fi

% \subsection{Secondary Objectives}







With new net lists, circuits, and simplified file formats,
many pieces were now in place to accerate research
in physical design.  

In 2005, ISPD began to hold annual contests to evaluate different
approaches to key physical design problems.  For circuit placement,
the contests have occurred in 2005, 2006, 2011, 2014, 2015, with 2016
and 2017 focusing on placement for field programmable gate arrays.

The contests draw entries from many research groups, and have
helped to form a community amongst students in the field, as
well as their advisors.  

\begin{table}
  \begin{tabular}{|r|l|}\hline
    Year & Contest \\ \hline
    2005/2006 & Placement \\ \hline
    2007/2008 & Global Routing \\ \hline
    2009 & Clock Network Synthesis \\ \hline    
    2010 & High Performance Clock Network Synthesis \\ \hline    
    2011 & Routability-Driven Placement \\ \hline
    2012/2013 & Discrete Gate Sizing \\ \hline
    2014 & Detailed Routing-Driven Placement \\ \hline    
    2015 & Blockage-Aware Detailed Routing-Driven Placement \\ \hline
    2016 & Routability-Driven FPGA Placement \\ \hline
    2017 & Clock-Aware FPGA Placement \\ \hline    
    2018/2019 & Initial Detailed Routing \\ \hline    
    2020 & Wafer-Scale Deep Learning Accelerator Placement \\ \hline
    2021 & Wafer-Scale Physics Modeling \\ \hline
  \end{tabular}
  \caption{The ISPD Contests.}
  \label{tab:ispdcontest}
\end{table}

\subsection{Mixed Size Placement, 2005, 2006}

{\bf Gi-Joon}.  
\cite{ISPD05_contest}
Details here about ISPD 2005.  Cite relevant papers.
Benchmarks are adaptec, bigblue versions.  Legal2.pl script to
check legality.  Nine teams competing.
Fixed macros, from 200k to 2.1 million cells.

2006 adds target density, newblue designs.  Ten teams.  

\subsection{Routability, 2011}

\input natarajan.tex
Details, cite some papers.

\subsection{Detail Routing Driven Placement, 2014, 2015}

Details, cite some papers.
Detail Routing.
{\bf Ismail?}



\subsection{FPGA Placement 2016, 2017}

FPGA placement became the topic of ISPD Contest for 2016 and 2017. As
FPGA hardware technology advances and FPGA design sizes increase, the
core EDA algorithms including place and route face greater
challenges. Traditional academic FPGA placement study was primarily
based on benchmarks in VPN era. From modern FPGA design point of view,
these benchmarks are relatively small and the underlying FPGA
architecture is over simplified. A new set of benchmarks mapped to
latest commercial FPGAs can draw attention from academic research
groups.

In ISPD 2016 Xilinx held Routability-Driven FPGA Placement Contest
\cite{sy1}[1]. This is the first FPGA placement congest aiming on routability,
with benchmarks mapped on state-of-the-art commercial FPGA
architecture based on 20nm technology. The contest attracted 19
academic teams, 12 of them submitted final placer into
benchmarking. Contesters' placers were tested on a set of 12
testcases, with largest size at 1.1 million movable instances. The
placement quality is measured by Vivado router in Xilinx tool flow. If
the placement passes legality check and it is routed successfully,
total routed wirelength is used as the key metric. The total runtime
of place/route also matters. It serves as a scaling factor impacting
the metric by +/-10 percent.  UTPlacer\cite{sy2} [2] (from University of Texas
Austin), RippleFPGA\cite{sy3} [3] (from Chinese University of Hong Kong) and
GPlace\cite{sy4} [4] (from University of Guelph) won the first, second and third
place, respectively.

ISPD 2017 contest, Clock Aware FPGA Placement Contest\cite{sy5} [5], is an
extension from 2016’s topic. Clocking network in FPGA device poses a
major constraint to placement problem, because FPGA architecture
designers need to find a balance between reducing clock network area
and giving place/route flexibility. The problem becomes very
challenging for modern FPGA designs with many clocks. 9 teams
submitted their placers to compete. The final winners are UTPlaceF 2.0
\cite{sy6}[6] (from University of Texas Austin), NTUfplace\cite{sy7} [7] (from National
Taiwan University) and RippleFPGA\cite{sy8} [8] (from Chinese University of Hong
Kong).

Two ISPD FPGA placement contests triggered a lot of academic research
in the subsequent years. Benchmarks released in the contests, together
with the industrial tool supported evaluation flow, set up a perfect
platform for researchers to try out various placement
algorithms. There are successes on better placement quality\cite{sy9} [9],
faster runtime, algorithm parallelization\cite{sy10,sy11} [10,11], machine-learning
enhancement\cite{sy12} [12].



\iffalse
\subsection{Deep Learning Accelerator Placement, 2020}

Include this?  Not really placement, but placement-ish?
\fi


\section{From Benchmarks to Flows}

In the past few years, there have been increasing
numbers of open-source circuit designs,
providing a source 
for new benchmarks, and a way to evaluate entire
RTL-to-GDS flows.  Robust software frameworks for
parsing industrial file formats are available,
and there are open-source tools for most steps
in a flow.

\iffalse

Striking a balance between objectives.  Industry groups
would certainly like a production-ready tool, but this is
something that a small team of graduate students can't
build quickly.

Need to capture the essence of a problem, while keeping it
tractable.  Make the benchmark hard to game, so that solutions
actually resemble what we might want ``in practice.''

Trade-off on using library for parsing -- locks into a build
system, sometimes a language and set of tools.  Simple
file formats, by contrast, may lose the essential elements
that matter for an industrial design.

Evaluators, with painstaking detail, are important.

Complex tool flows for evaluation are trouble.

\fi


% \subsection{The OpenROAD}

On significant effort is the OpenROAD\cite{Ajayi19} project,
working to create a complete set of tools for RTL-to-GDS.

% Section on RDF
\input jinwook.tex


\section{Concluding Comments}


Certainly, much has changed over the years.  Preas\cite{Preas87}
noted in 1987 that some circuits with over 10,000 cells were becoming
commonplace -- challenging to handle because representing them
``may require a substantial fraction of a megabyte for storage.''
Circuits of this size might seem absurdly small today -- but they
were in fact challenging for the era.

It's easy to forget -- but not so long ago, the world wide web was not
ubiquitous. Getting access to benchmarks, even if they were ``publicly
available,'' required knowing who to ask, where to look, and the
navigation of anonymous FTP servers -- and often, data was
exchanged with magnetic tapes sent through the physical mail.
Disk space, processor cycles,
and memory, were all in short supply -- even with access to
benchmarks, it might not be possible to do anything with them.  In
this era, nearly everyone has a smart phone with a blazingly fast
processor, nearly infinite disk space, and vast amounts of RAM on
their workstations.  Many of the engineers working today started their
careers with punch cards, paper terminals, and, if they were lucky,
floppy disks.

The research field has matured, and the community has grown
significantly.  For physical design, the contests held annually
at ISPD have been of tremendous benefit -- new benchmarks, organized
and curated by industry leaders, are made available.  These
new benchmarks track the leading technological edge, and help
guide the academic community towards the most pressing problems.
These benchmarks are often simplified, making an ideal platform
for graduate students to gain understanding and insight, without
becoming overwhelmed.

With the availability of complex circuit designs and tools, all in
open-source format, benchmarking of an entire design flow is possible --
and this is becoming more common.  Keeping some focus on simplified
problems at individual stages of a flow remains useful; we 
anticipate a range of benchmarks and metrics to be relevant over
the years to come.




\balance
\bibliographystyle{unsrt}
\bibliography{unify,stephen}


\end{document}

